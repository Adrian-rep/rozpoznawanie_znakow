# -*- coding: utf-8 -*-
"""GS_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mVl1lvIbf1kBWjZUVAd4oWO6XaDDKkYQ
"""

import tensorflow as tf
from keras.models import Sequential, save_model
from keras.layers import Conv2D, MaxPool2D, MaxPooling2D, Dense, Dropout, Activation, Flatten
import cv2 
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import os
from sklearn.model_selection import train_test_split
from keras.utils.np_utils import to_categorical
from google.colab import drive
from keras import regularizers
from tensorflow.keras.callbacks import EarlyStopping
# from keras.preprocessing.image import ImageDataGenerator
# from tensorflow.keras.utils import array_to_img, img_to_array

drive.mount('/content/drive')

"""## Pobranie danych"""

data_path = '/content/drive/MyDrive/german_sign_classification/data/'
label_path = '/content/drive/MyDrive/german_sign_classification/labels.csv'

class_list = os.listdir(data_path)
len_class_list = len(class_list)

def colect_data(data_path):
    images = []
    classes = []
    class_list = os.listdir(data_path)

    print(f"Total Classes Detected: {len_class_list}")
    print("Importing Classes.....")

    for class_num in range(len_class_list):
        pic_list = os.listdir(data_path  + f'/class_ ({class_num})')
        for img in pic_list:
            cur_img = cv2.imread(data_path + f'/class_ ({class_num})' + "/" + img)
            if cur_img is None:
                print('img is none')
            cur_img = cv2.resize(cur_img, (28, 28))
            images.append(cur_img)
            classes.append(class_num)
        print(class_num, end=" ")
    print(" ")
    images = np.array(images)
    classes = np.array(classes)
    return images, classes

images, classes = colect_data(data_path)

print(images.shape)
print(classes.shape)

plt.imshow(images[2])

"""## Podział danych na zbiory"""

X_train, X_test, y_train, y_test = train_test_split(images, classes, test_size=0.2)
X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=0.2)

print('Shapes')
print('===========================')
print(f"X_train: {X_train.shape}")
print(f"y_train: {y_train.shape}")
print(" ")
print(f"X_validation: {X_validation.shape}")
print(f"y_validation: {y_validation.shape}")
print(" ")
print(f"X_test: {X_test.shape}")
print(f"y_test: {y_test.shape}")
print('===========================')

"""### Klasy """

labels = pd.read_csv(label_path)
labels.info()

labels.sample(4)

"""## Rozkład poszczególnych klas """

def show_distribution(labels, X_train, y_train):
    class_list = os.listdir(data_path)
    num_of_samples = []
    for idx, _ in labels.iterrows():
        x_selected = X_train[np.where(y_train == idx)]
        num_of_samples.append(len(x_selected))
        
    plt.figure(figsize=(12, 4))
    plt.bar(range(0, len(class_list)), num_of_samples)
    plt.title("Distribution of the training dataset")
    plt.xlabel("Class number")
    plt.ylabel("Number of images")
    plt.grid()
    plt.show()

show_distribution(labels, X_train, y_train)

# Po dodaniu obraów za pomocą ImageDataGenerator, model działał gorzej 
# Sposób wykonania na końcu notatnika

"""### Preprocessing danych"""

def preprocessing(img):
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  
    img = cv2.equalizeHist(img) # It is a method that improves the contrast in an image  
    img = img / 255
    return img

X_train = np.array(list(map(preprocessing, X_train))) 
X_validation = np.array(list(map(preprocessing, X_validation)))
X_test = np.array(list(map(preprocessing, X_test)))

plt.imshow(X_train[0])

"""### Dodanie kolejnego wymiaru """

X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)
X_validation = X_validation.reshape(X_validation.shape[0], X_validation.shape[1], X_validation.shape[2], 1)
X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)

y_train = to_categorical(y_train, len_class_list)
y_validation = to_categorical(y_validation, len_class_list)
y_test = to_categorical(y_test, len_class_list)

print('Shapes')
print('===========================')
print(f"X_train: {X_train.shape}")
print(f"y_train: {y_train.shape}")
print(" ")
print(f"X_validation: {X_validation.shape}")
print(f"y_validation: {y_validation.shape}")
print(" ")
print(f"X_test: {X_test.shape}")
print(f"y_test: {y_test.shape}")
print('===========================')

"""### Budowa modelu """

EarlyStop = EarlyStopping(monitor='val_loss', 
                          patience=5,
                          verbose=1)

def CNN_model_1():
    model = Sequential()
    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))
    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
    model.add(MaxPool2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))
    
    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))
    model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))
    model.add(MaxPool2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))
    
    model.add(Flatten())
    model.add(Dense(128, activation='relu'))
    model.add(Dense(len_class_list, activation = 'softmax'))

    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])
    
    return model

model_1 = CNN_model_1()
print(model_1.summary())

history = model_1.fit(X_train, y_train,
              batch_size= 16,
              epochs= 30,
              validation_data= (X_test, y_test),
              callbacks=[EarlyStop],
              shuffle=True)

plt.figure(1)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.legend(['training', 'validation'])
plt.title('loss')
plt.xlabel('epoch')

plt.figure(2)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.legend(['training', 'validation'])
plt.title('Acurracy')
plt.xlabel('epoch')
plt.show()
score = model_1.evaluate(X_test, y_test, verbose=0)
print('Test Score:', score[0])
print('Test Accuracy:', score[1])

tf.keras.models.save_model(model_1, "/content/drive/MyDrive/german_sign_classification/CNN_model_1_main_colab.hdf5")

def CNN_model_2():
    model = Sequential()
    model.add(Conv2D(32, (1, 1), padding='same', input_shape=X_train.shape[1:], activation='relu'))
    model.add(Conv2D(32, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))

    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))
    model.add(Conv2D(64, (3, 3), activation='relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))

    model.add(Flatten())
    model.add(Dense(392, kernel_regularizer=regularizers.l2(0.01), activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(len_class_list, activation='softmax'))
    
    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])
    
    return model

model_2 = CNN_model_2()
print(model_2.summary())

history = model_2.fit(X_train, y_train,
              batch_size= 16,
              epochs= 50,
              validation_data= (X_test, y_test),
              callbacks=[EarlyStop],
              shuffle=True)

plt.figure(1)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.legend(['training', 'validation'])
plt.title('loss')
plt.xlabel('epoch')

plt.figure(2)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.legend(['training', 'validation'])
plt.title('Acurracy')
plt.xlabel('epoch')
plt.show()
score = model_2.evaluate(X_test, y_test, verbose=0)
print('Test Score:', score[0])
print('Test Accuracy:', score[1])

"""### Zapisanie modelu """

tf.keras.models.save_model(model_2, "/content/drive/MyDrive/german_sign_classification/CNN_model_main_2_colab.hdf5")

"""==============================================================================================================

### ImageDataGenerator
"""

num_of_samples = []
for idx, _ in labels.iterrows():
    print(idx)
    #x_selected = X_train[np.where(y_train == idx)]
    #num_of_samples.append(len(x_selected))

    class_list = os.listdir(data_path)
    num_of_samples = []
    for idx, _ in labels.iterrows():
        x_selected = X_train[np.where(y_train == idx)]
        num_of_samples.append(len(x_selected))

MAX_NUM_OF_SAMPLES = max(num_of_samples)
MAX_NUM_OF_SAMPLES

datagen = ImageDataGenerator(
rotation_range=40,
width_shift_range=0.2,
height_shift_range=0.2,
shear_range=0.2,
zoom_range=0.2,
horizontal_flip=True,
fill_mode='nearest')

test_images = []
size_of_labels = []

for i in range(0, len(class_list)):
    pic_list = os.listdir(data_path  + f'/class_ ({i})') # 0, 1, 2, 3 ...
    size_of_labels.append(len(pic_list))
    for idx in pic_list:
        cur_img = cv2.imread(data_path + f'/class_ ({i})' + "/" + idx)
        test_images.append(cur_img)
        break

dir_path = r'C:\Users\26609\Desktop\german_sign\Training'
num_of_samples = []
for idx, pic in enumerate(test_images):
    img = img_to_array(pic)  # convert image to numpy arry
    img = img.reshape((1,) + img.shape)  # reshape imag
    for batch in datagen.flow(img, save_to_dir= dir_path + f'/class_ ({idx})', save_prefix='test_image', save_format='ppm'):  # this loops runs forever until we break, saving images to current directory with specified prefix
        size_of_labels[idx] += 1
        if size_of_labels[idx] >= MAX_NUM_OF_SAMPLES: 
            break

"""#### Rozkład danych po wykonaniu

![obraz_2022-06-24_104245104.png](attachment:obraz_2022-06-24_104245104.png)
"""

